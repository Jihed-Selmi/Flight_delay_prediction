{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This Jupyter notebook is dedicated to the preprocessing of data collected from three different sources: flights, weather, and reviews. The purpose of this notebook is to clean and prepare the data for further analysis or machine learning tasks. Preprocessing includes handling missing values, identifying and dealing with outliers, and merging the datasets into a single cohesive structure.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The goal of this preprocessing step is to ensure that the datasets are:\n",
    "- **Clean**: Free from inaccuracies and inconsistencies.\n",
    "- **Complete**: Missing values are addressed appropriately.\n",
    "- **Conformant**: Data is standardized to expected formats.\n",
    "- **Consolidated**: Relevant data from all three sources are combined logically.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "The datasets being processed are:\n",
    "1. **Flights**: Contains information about flight schedules, delays, and other related attributes.\n",
    "2. **Weather**: Includes weather conditions at different airport locations.\n",
    "3. **Reviews**: Comprises customer reviews and ratings for the flights.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps\n",
    "The preprocessing will be conducted in the following order:\n",
    "1. **Initial Exploration**: Quick overview of the datasets to understand the structure and content.\n",
    "2. **Data Cleaning**:\n",
    "    - Removing duplicates.\n",
    "    - Fixing structural errors (e.g., mislabeled classes, wrong data types).\n",
    "3. **Handling Missing Values**:\n",
    "    - Identifying missing values.\n",
    "    - Deciding on a strategy to handle missing values (e.g., imputation, removal).\n",
    "4. **Outlier Detection**:\n",
    "    - Statistical methods to detect outliers.\n",
    "    - Deciding on a strategy to handle outliers (e.g., trimming, capping, or correcting).\n",
    "5. **Data Integration**:\n",
    "    - Aligning datasets by common attributes.\n",
    "    - Merging datasets into a unified table.\n",
    "6. **Data Transformation**:\n",
    "    - Normalization or scaling.\n",
    "    - Encoding categorical variables.\n",
    "7. **Final Inspection**:\n",
    "    - Ensuring the processed data meets the initial objectives.\n",
    "    - Storing the preprocessed data in a suitable format.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Libraries\n",
    "- `Spark`: For distributed data processing.\n",
    "- `PySpark`: Python API for Spark.\n",
    "- `Pandas`: For data manipulation within Spark jobs.\n",
    "- `Matplotlib`/`Seaborn`: For visualizations (if needed, considering the size of data).\n",
    "- `MLlib`: Sparkâ€™s machine learning library (if preprocessing involves feature selection or dimensionality reduction).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat, lit, split, expr, to_date, to_timestamp, date_format, lower, concat_ws, regexp_replace, when, regexp_replace, trim, regexp_extract, hour, mean, minute, lpad\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flights_processing():\n",
    "    \"\"\"\n",
    "    Transforms flight data by cleaning and structuring. Removes unnecessary columns, normalizes dates and times, \n",
    "    extracts key information from strings, and filters based on flight status. Assumes data is loaded from a CSV \n",
    "    with a predefined schema.\n",
    "\n",
    "    Returns:\n",
    "        flights_df (DataFrame): A Spark DataFrame with processed flights information.\n",
    "    \"\"\"\n",
    "    # Initialize Spark Session\n",
    "    spark = SparkSession.builder.appName(\"FlightsDataProcessing\")\\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Define the schema for reading the CSV file\n",
    "    schema = StructType([\n",
    "        StructField(\"aircraft\", StringType(), True),\n",
    "        StructField(\"temp1\", StringType(), True),\n",
    "        StructField(\"temp2\", StringType(), True),\n",
    "        StructField(\"date\", StringType(), True),\n",
    "        StructField(\"from\", StringType(), True),\n",
    "        StructField(\"to\", StringType(), True),\n",
    "        StructField(\"flight\", StringType(), True),\n",
    "        StructField(\"flight_time\", StringType(), True),\n",
    "        StructField(\"scheduled_time_departure\", StringType(), True),\n",
    "        StructField(\"actual_time_departure\", StringType(), True),\n",
    "        StructField(\"scheduled_time_arrival\", StringType(), True),\n",
    "        StructField(\"temp3\", StringType(), True),\n",
    "        StructField(\"status\", StringType(), True),\n",
    "        StructField(\"temp4\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "    # Load the data\n",
    "    flights_df = spark.read.csv('./data/history/flights.csv', schema=schema, header=False)\n",
    "    \n",
    "    # Data Preprocessing Steps\n",
    "\n",
    "    # 1. Remove unnecessary columns\n",
    "    flights_df = flights_df.drop(\"temp1\", \"temp2\", \"temp3\", \"temp4\")\n",
    "    \n",
    "    # 2. Convert date to DateType\n",
    "    flights_df = flights_df.withColumn(\"date\", to_date(\"date\", \"dd MMM yyyy\"))\n",
    "\n",
    "    # 7. Split 'status' into new 'status' and 'actual_time_arrival'\n",
    "    split_col = split(col(\"status\"), \" \")\n",
    "    flights_df = flights_df.withColumn(\"actual_time_arrival\", expr(\"substring(status, length(status) - 4, 5)\"))\n",
    "    flights_df = flights_df.withColumn(\"status\", split_col.getItem(0))\n",
    "\n",
    "    \n",
    "    # 8. Filter rows to only include statuses 'Departed' or 'Arrived'\n",
    "    flights_df = flights_df.filter(col(\"status\").rlike(\"Landed\"))\n",
    "\n",
    "    \n",
    "    # 3. Convert 'time' to TimestampType assuming it contains AM/PM\n",
    "    # Concatenate 'date' with 'time' before converting to timestamp for 'expected_time'\n",
    "    # This ensures the timestamp includes the correct date instead of defaulting to '1970-01-01'\n",
    "    flights_df = flights_df.withColumn(\n",
    "        \"flight_time\", \n",
    "        to_timestamp(concat_ws(\" \", date_format(col(\"date\"), \"yyyy-MM-dd\"), col(\"flight_time\")), \"yyyy-MM-dd HH:mm\")\n",
    "    ).withColumn(\n",
    "        \"scheduled_time_departure\", \n",
    "        to_timestamp(concat_ws(\" \", date_format(col(\"date\"), \"yyyy-MM-dd\"), col(\"scheduled_time_departure\")), \"yyyy-MM-dd HH:mm\")\n",
    "    ).withColumn(\n",
    "        \"actual_time_departure\", \n",
    "        to_timestamp(concat_ws(\" \", date_format(col(\"date\"), \"yyyy-MM-dd\"), col(\"actual_time_departure\")), \"yyyy-MM-dd HH:mm\")\n",
    "    ).withColumn(\n",
    "        \"scheduled_time_arrival\", \n",
    "        to_timestamp(concat_ws(\" \", date_format(col(\"date\"), \"yyyy-MM-dd\"), col(\"scheduled_time_arrival\")), \"yyyy-MM-dd HH:mm\")\n",
    "    ).withColumn(\n",
    "        \"actual_time_arrival\", \n",
    "        to_timestamp(concat_ws(\" \", date_format(col(\"date\"), \"yyyy-MM-dd\"), col(\"actual_time_arrival\")), \"yyyy-MM-dd HH:mm\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 4. Extract city from 'from' and 'to' and convert it to lowercase\n",
    "    flights_df = flights_df.withColumn(\"from_city\", lower(split(col(\"from\"), \" \\\\(\")[0])) \\\n",
    "                           .withColumn(\"to_city\", lower(split(col(\"to\"), \" \\\\(\")[0]))\n",
    "\n",
    "    # 5. Extract airport code from 'from' and 'to'\n",
    "    flights_df = flights_df.withColumn(\"from\", lower(split(col(\"from\"), \" \\\\(\")[1].substr(0, 3))) \\\n",
    "                           .withColumn(\"to\", lower(split(col(\"to\"), \" \\\\(\")[1].substr(0, 3))) \\\n",
    "\n",
    "    \n",
    "    # Add a new column 'rounded_hour' that represents the closest hour to the scheduled time arrival\n",
    "    flights_df = flights_df.withColumn(\"hour\", hour(\"scheduled_time_arrival\")) \\\n",
    "        .withColumn(\"minute\", minute(\"scheduled_time_arrival\")) \\\n",
    "        .withColumn(\"rounded_hour\",\n",
    "                        when(col(\"minute\") >= 30, expr(\"hour + 1\"))\n",
    "                        .otherwise(col(\"hour\"))\n",
    "                    ) \\\n",
    "        .drop(\"hour\", \"minute\")\n",
    "    \n",
    "    # Adjust for the case where adding 1 to the hour results in 24\n",
    "    flights_df = flights_df.withColumn(\"rounded_hour\",\n",
    "                    when(col(\"rounded_hour\") == 24, 0)\n",
    "                    .otherwise(col(\"rounded_hour\"))\n",
    "                    )\n",
    "    \n",
    "    # Convert 'rounded_hour' to a string with two digits\n",
    "    hour_str = lpad(col(\"rounded_hour\"), 2, '0')\n",
    "    \n",
    "    # Concatenate 'date' and 'hour_str' to form a datetime string\n",
    "    datetime_str = concat_ws(\" \", col(\"date\"), hour_str)\n",
    "\n",
    "    # Append \":00:00\" to represent minutes and seconds, forming a full datetime string\n",
    "    datetime_str = concat_ws(\":\", datetime_str, lit(\"00\"), lit(\"00\"))\n",
    "\n",
    "    # Convert the datetime string to a timestamp\n",
    "    flights_df = flights_df.withColumn(\"rounded_hour\", to_timestamp(datetime_str, \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "    # 10. Remove duplicates\n",
    "    flights_df = flights_df.dropDuplicates()\n",
    "\n",
    "    flights_df = flights_df.withColumn('airport', col('to'))\n",
    "\n",
    "    # 11. Add status and delay_time\n",
    "    # Calculate delay in minutes\n",
    "    flights_df = flights_df.withColumn(\"delay_time\", \n",
    "                                (col(\"actual_time_arrival\").cast(\"long\") - col(\"scheduled_time_arrival\").cast(\"long\")) / 60)\n",
    "    \n",
    "    # Define status based on delay_time\n",
    "    flights_df = flights_df.withColumn(\"status\", when(col(\"delay_time\") > 15, \"Delayed\").otherwise(\"On Time\"))\n",
    "    \n",
    "    # Check the schema of columns\n",
    "    flights_df.printSchema()\n",
    "\n",
    "    # Display the processed DataFrame\n",
    "    flights_df.show(truncate=False)\n",
    "\n",
    "    # Save to csv\n",
    "    path = \"./data/processed/flights\"\n",
    "    flights_df.coalesce(1).write.csv(path=path, mode=\"overwrite\", header=True)\n",
    "    \n",
    "    # Return the processed DataFrame\n",
    "    return flights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aircraft: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- from: string (nullable = true)\n",
      " |-- to: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- flight_time: timestamp (nullable = true)\n",
      " |-- scheduled_time_departure: timestamp (nullable = true)\n",
      " |-- actual_time_departure: timestamp (nullable = true)\n",
      " |-- scheduled_time_arrival: timestamp (nullable = true)\n",
      " |-- status: string (nullable = false)\n",
      " |-- actual_time_arrival: timestamp (nullable = true)\n",
      " |-- from_city: string (nullable = true)\n",
      " |-- to_city: string (nullable = true)\n",
      " |-- rounded_hour: timestamp (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- delay_time: double (nullable = true)\n",
      "\n",
      "+--------+----------+----+---+------+-------------------+------------------------+---------------------+----------------------+-------+-------------------+-----------------+----------+-------------------+-------+----------+\n",
      "|aircraft|date      |from|to |flight|flight_time        |scheduled_time_departure|actual_time_departure|scheduled_time_arrival|status |actual_time_arrival|from_city        |to_city   |rounded_hour       |airport|delay_time|\n",
      "+--------+----------+----+---+------+-------------------+------------------------+---------------------+----------------------+-------+-------------------+-----------------+----------+-------------------+-------+----------+\n",
      "|se-rrb  |2024-03-20|arn |szg|D84471|2024-03-20 01:50:00|2024-03-20 10:15:00     |2024-03-20 10:28:00  |2024-03-20 12:25:00   |On Time|2024-03-20 12:18:00|stockholm        |salzburg  |2024-03-20 12:00:00|szg    |-7.0      |\n",
      "|se-rrb  |2024-03-03|ume |arn|D84014|2024-03-03 00:50:00|2024-03-03 17:45:00     |2024-03-03 17:54:00  |2024-03-03 18:50:00   |On Time|2024-03-03 18:44:00|umea             |stockholm |2024-03-03 19:00:00|arn    |-6.0      |\n",
      "|se-rrb  |2023-12-03|arn |lla|D84039|2023-12-03 01:07:00|2023-12-03 13:05:00     |2023-12-03 13:18:00  |2023-12-03 14:25:00   |On Time|2023-12-03 14:24:00|stockholm        |lulea     |2023-12-03 14:00:00|lla    |-1.0      |\n",
      "|se-rrb  |2023-12-03|lla |arn|D84036|2023-12-03 01:04:00|2023-12-03 10:15:00     |2023-12-03 10:31:00  |2023-12-03 11:35:00   |On Time|2023-12-03 11:35:00|lulea            |stockholm |2023-12-03 12:00:00|arn    |0.0       |\n",
      "|se-rrb  |2023-08-11|pmi |arn|D84214|2023-08-11 03:13:00|2023-08-11 20:05:00     |2023-08-11 20:05:00  |2023-08-11 23:45:00   |On Time|2023-08-11 23:18:00|palma de mallorca|stockholm |2023-08-11 00:00:00|arn    |-27.0     |\n",
      "|se-rrb  |2023-08-02|arn |lla|D84035|2023-08-02 01:07:00|2023-08-02 08:40:00     |2023-08-02 08:52:00  |2023-08-02 10:00:00   |On Time|2023-08-02 09:59:00|stockholm        |lulea     |2023-08-02 10:00:00|lla    |-1.0      |\n",
      "|se-rrb  |2023-07-23|arn |lla|D84041|2023-07-23 01:05:00|2023-07-23 13:40:00     |2023-07-23 14:01:00  |2023-07-23 15:00:00   |On Time|2023-07-23 15:07:00|stockholm        |lulea     |2023-07-23 15:00:00|lla    |7.0       |\n",
      "|se-rrb  |2023-07-03|arn |ber|D84505|2023-07-03 01:23:00|2023-07-03 12:50:00     |2023-07-03 12:57:00  |2023-07-03 14:25:00   |On Time|2023-07-03 14:20:00|stockholm        |berlin    |2023-07-03 14:00:00|ber    |-5.0      |\n",
      "|se-rrb  |2023-06-25|hel |arn|D82618|2023-06-25 00:45:00|2023-06-25 21:15:00     |2023-06-25 21:17:00  |2023-06-25 21:15:00   |On Time|2023-06-25 21:02:00|helsinki         |stockholm |2023-06-25 21:00:00|arn    |-13.0     |\n",
      "|se-rrb  |2023-06-11|arn |cdg|D84311|2023-06-11 02:05:00|2023-06-11 06:50:00     |2023-06-11 06:54:00  |2023-06-11 09:35:00   |On Time|2023-06-11 08:59:00|stockholm        |paris     |2023-06-11 10:00:00|cdg    |-36.0     |\n",
      "|se-rrb  |2023-05-21|alc |cph|D85372|2023-05-21 02:49:00|2023-05-21 16:40:00     |2023-05-21 16:55:00  |2023-05-21 19:55:00   |On Time|2023-05-21 19:44:00|alicante         |copenhagen|2023-05-21 20:00:00|cph    |-11.0     |\n",
      "|se-rrb  |2023-05-02|lla |arn|D84046|2023-05-02 01:05:00|2023-05-02 19:30:00     |2023-05-02 19:31:00  |2023-05-02 20:50:00   |On Time|2023-05-02 20:36:00|lulea            |stockholm |2023-05-02 21:00:00|arn    |-14.0     |\n",
      "|se-rrb  |2023-04-26|hau |alc|D85329|2023-04-26 03:09:00|2023-04-26 19:45:00     |2023-04-26 19:51:00  |2023-04-26 23:15:00   |On Time|2023-04-26 23:00:00|haugesund        |alicante  |2023-04-26 23:00:00|alc    |-15.0     |\n",
      "|se-rrb  |2023-04-09|arn |lis|D84277|2023-04-09 03:54:00|2023-04-09 13:20:00     |2023-04-09 13:32:00  |2023-04-09 16:45:00   |On Time|2023-04-09 16:26:00|stockholm        |lisbon    |2023-04-09 17:00:00|lis    |-19.0     |\n",
      "|f-grhv  |2024-03-19|cdg |otp|AF1088|2024-03-19 02:29:00|2024-03-19 18:15:00     |2024-03-19 18:39:00  |2024-03-19 22:05:00   |On Time|2024-03-19 22:08:00|paris            |bucharest |2024-03-19 22:00:00|otp    |3.0       |\n",
      "|f-grhv  |2024-03-16|tos |cdg|AF1221|2024-03-16 03:10:00|2024-03-16 15:55:00     |2024-03-16 16:51:00  |2024-03-16 19:55:00   |On Time|2024-03-16 20:01:00|tromso           |paris     |2024-03-16 20:00:00|cdg    |6.0       |\n",
      "|f-grhv  |2023-12-15|cdg |mad|AF1600|2023-12-15 01:27:00|2023-12-15 13:15:00     |2023-12-15 13:40:00  |2023-12-15 15:25:00   |On Time|2023-12-15 15:06:00|paris            |madrid    |2023-12-15 15:00:00|mad    |-19.0     |\n",
      "|f-grhv  |2023-11-22|cdg |ber|AF1834|2023-11-22 01:28:00|2023-11-22 15:45:00     |2023-11-22 15:57:00  |2023-11-22 17:25:00   |On Time|2023-11-22 17:25:00|paris            |berlin    |2023-11-22 17:00:00|ber    |0.0       |\n",
      "|f-grhv  |2023-10-16|alg |ory|AF7541|2023-10-16 01:59:00|2023-10-16 10:50:00     |2023-10-16 10:44:00  |2023-10-16 14:15:00   |On Time|2023-10-16 13:43:00|algiers          |paris     |2023-10-16 14:00:00|ory    |-32.0     |\n",
      "|f-grhv  |2023-04-20|tls |ory|AF6145|2023-04-20 01:01:00|2023-04-20 21:00:00     |2023-04-20 21:03:00  |2023-04-20 22:20:00   |On Time|2023-04-20 22:03:00|toulouse         |paris     |2023-04-20 22:00:00|ory    |-17.0     |\n",
      "+--------+----------+----+---+------+-------------------+------------------------+---------------------+----------------------+-------+-------------------+-----------------+----------+-------------------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the flights processing function\n",
    "flights_df = flights_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| to|count|\n",
      "+---+-----+\n",
      "|dfw| 6543|\n",
      "|ord| 6507|\n",
      "|hnd| 6347|\n",
      "|fra| 6020|\n",
      "|lhr| 5486|\n",
      "|den| 5100|\n",
      "|cdg| 4928|\n",
      "|clt| 4257|\n",
      "|pvg| 4082|\n",
      "|iah| 4048|\n",
      "|mia| 4002|\n",
      "|del| 3966|\n",
      "|can| 3932|\n",
      "|ams| 3619|\n",
      "|sgn| 3566|\n",
      "|kmg| 3551|\n",
      "|lax| 3410|\n",
      "|ewr| 3355|\n",
      "|yyz| 3324|\n",
      "|mad| 3322|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.groupBy('to').count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aircrafts info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aircrafts_info_processing():\n",
    "    \"\"\"\n",
    "    Processes airaircraftport information data, cleaning and converting specific columns to proper data types.\n",
    "    N/A values are treated as null, and numeric fields are cast to their respective types.\n",
    "    \n",
    "    Returns:\n",
    "        aircraft_info_df (DataFrame): A Spark DataFrame with processed aircraft information.\n",
    "    \"\"\"\n",
    "    # Initialize Spark Session with legacy time parser policy for compatibility\n",
    "    spark = SparkSession.builder.appName(\"AircraftsInfoDataProcessing\") \\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Define the schema for the airport information data\n",
    "    schema = StructType([\n",
    "        StructField(\"msn\", StringType(), True),\n",
    "        StructField(\"type\", StringType(), True),\n",
    "        StructField(\"aircraft\", StringType(), True),\n",
    "        StructField(\"airline\", StringType(), True),\n",
    "        StructField(\"first_flight\", StringType(), True),\n",
    "        StructField(\"photo\", StringType(), True),\n",
    "    ])\n",
    "    \n",
    "    # Load the data from a CSV file, ensuring correct schema application\n",
    "    aircraft_info_df = spark.read.csv('./data/history/aircrafts_info.csv', schema=schema, header=False)\n",
    "\n",
    "    aircraft_info_df = aircraft_info_df.drop(\"photo\")\n",
    "\n",
    "    age_pattern = r\"\\((\\d+) years\\)\"\n",
    "\n",
    "    # Add a new column \"age\" that extracts the age part and converts it to an integer\n",
    "    aircraft_info_df = aircraft_info_df.withColumn(\"age\", regexp_extract(col(\"first_flight\"), age_pattern, 1).cast(\"integer\")).drop('first_flight')\n",
    "\n",
    "    \n",
    "    # Convert the 'aircraft' column to lowercase\n",
    "    aircraft_info_df = aircraft_info_df.withColumn(\"aircraft\", lower(aircraft_info_df[\"aircraft\"]))\n",
    "\n",
    "    # Check the schema of columns\n",
    "    aircraft_info_df.printSchema()\n",
    "\n",
    "    aircraft_info_df.show(truncate=False)\n",
    "\n",
    "    return aircraft_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msn: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- aircraft: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n",
      "+--------+----+--------+-----------------------+----+\n",
      "|msn     |type|aircraft|airline                |age |\n",
      "+--------+----+--------+-----------------------+----+\n",
      "|09108   |A21N|vn-a508 |Vietnam Airlines       |4   |\n",
      "|42175   |B739|n68811  |United Airlines        |10  |\n",
      "|64301   |B739|n292ak  |Alaska Airlines        |5   |\n",
      "|39392   |B738|b-5543  |Shandong Airlines      |13  |\n",
      "|11468   |A21N|tc-rdu  |Pegasus                |NULL|\n",
      "|4008    |DH8D|5y-vvu  |Bluebird Aviation      |24  |\n",
      "|32937   |B737|b-2620  |China Southern Airlines|19  |\n",
      "|567     |A310|ep-mnv  |Mahan Air              |33  |\n",
      "|259     |A388|a6-evj  |Emirates               |5   |\n",
      "|145135  |E145|s5-acj  |Amelia                 |25  |\n",
      "|35965   |B738|n8695d  |Southwest Airlines     |7   |\n",
      "|33346   |B738|n339pl  |American Airlines      |6   |\n",
      "|11249   |A21N|tc-ltz  |AJet                   |NULL|\n",
      "|666     |DH8B|7t-vcs  |Tassili Airlines       |16  |\n",
      "|10243   |CRJ7|n770sk  |American Airlines      |18  |\n",
      "|1606    |A332|n375ha  |Hawaiian Airlines      |9   |\n",
      "|145122  |E145|fab6701 |Brazil - Air Force     |25  |\n",
      "|19000039|E190|n238jb  |JetBlue Airways        |17  |\n",
      "|11473   |A21N|hz-asac |Saudia                 |NULL|\n",
      "|29902   |B744|4k-bcv  |Silk Way West Airlines |17  |\n",
      "+--------+----+--------+-----------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aircraft_info_df = aircrafts_info_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Airports info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airports_info_processing():\n",
    "    \"\"\"\n",
    "    Processes airport information data, cleaning and converting specific columns to proper data types.\n",
    "    N/A values are treated as null, and numeric fields are cast to their respective types.\n",
    "    \n",
    "    Returns:\n",
    "        info_df (DataFrame): A Spark DataFrame with processed airport information.\n",
    "    \"\"\"\n",
    "    # Initialize Spark Session with legacy time parser policy for compatibility\n",
    "    spark = SparkSession.builder.appName(\"AirportsInfoDataProcessing\") \\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Define the schema for the airport information data\n",
    "    schema = StructType([\n",
    "        StructField(\"my_flightradar24_rating\", StringType(), True),\n",
    "        StructField(\"temp\", StringType(), True),  # Placeholder for column due to scraping error\n",
    "        StructField(\"arrival_delay_index\", StringType(), True),\n",
    "        StructField(\"departure_delay_index\", StringType(), True),\n",
    "        StructField(\"utc\", StringType(), True),\n",
    "        StructField(\"local\", StringType(), True),\n",
    "        StructField(\"airport\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "    # Load the data from a CSV file, ensuring correct schema application\n",
    "    info_df = spark.read.csv('./data/history/airports_info.csv', schema=schema, header=False)\n",
    "\n",
    "    # Drop the 'temp' column as it contains null values due to scraping errors\n",
    "    info_df = info_df.drop(\"temp\")\n",
    "\n",
    "    # Replace \"N/A\" string values with null across the DataFrame\n",
    "    info_df = info_df.na.replace(\"N/A\", None)\n",
    "\n",
    "    # Clean numeric fields and cast to correct types\n",
    "    info_df = info_df.withColumn(\"my_flightradar24_rating\", \n",
    "                                 regexp_replace(col(\"my_flightradar24_rating\"), \"[^0-9]\", \"\").cast(IntegerType())) \\\n",
    "                     .withColumn(\"arrival_delay_index\", col(\"arrival_delay_index\").cast(FloatType())) \\\n",
    "                     .withColumn(\"departure_delay_index\", col(\"departure_delay_index\").cast(FloatType()))\n",
    "    \n",
    "    # Extract the utc time part and convert it to a Spark timestamp format\n",
    "    info_df = info_df.withColumn(\"utc\", to_timestamp(regexp_extract(col(\"utc\"), \"(\\\\d{2}:\\\\d{2})\", 0), \"HH:mm\"))\n",
    "\n",
    "    # Convert local time to a Spark timestamp format\n",
    "    info_df = info_df.withColumn(\"local\", to_timestamp(concat(lit(\"1970-01-01 \"), col(\"local\")), \"yyyy-MM-dd hh:mm a\"))\n",
    "\n",
    "    # Calculate time difference utc-local\n",
    "    info_df = info_df.withColumn(\"time_diff\", col('utc')-col('local')).drop('utc', 'local')\n",
    "\n",
    "    # Remove duplicates\n",
    "    info_df = info_df.dropDuplicates()\n",
    "\n",
    "    # Check the schema of columns\n",
    "    info_df.printSchema()\n",
    "\n",
    "    # Display the processed DataFrame\n",
    "    info_df.show(truncate=False)\n",
    "\n",
    "    # Return the processed DataFrame\n",
    "    return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- my_flightradar24_rating: integer (nullable = true)\n",
      " |-- arrival_delay_index: float (nullable = true)\n",
      " |-- departure_delay_index: float (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- time_diff: interval day to second (nullable = true)\n",
      "\n",
      "+-----------------------+-------------------+---------------------+-------+------------------------------------+\n",
      "|my_flightradar24_rating|arrival_delay_index|departure_delay_index|airport|time_diff                           |\n",
      "+-----------------------+-------------------+---------------------+-------+------------------------------------+\n",
      "|92                     |0.3                |1.7                  |doh    |INTERVAL '-0 03:00:00' DAY TO SECOND|\n",
      "|63                     |0.4                |1.0                  |crl    |INTERVAL '-0 01:00:00' DAY TO SECOND|\n",
      "|72                     |0.4                |0.8                  |tia    |INTERVAL '-0 01:00:00' DAY TO SECOND|\n",
      "|81                     |0.4                |2.1                  |bru    |INTERVAL '-0 01:00:00' DAY TO SECOND|\n",
      "|77                     |0.4                |0.0                  |bah    |INTERVAL '-0 03:00:00' DAY TO SECOND|\n",
      "|85                     |0.4                |0.0                  |gyd    |INTERVAL '-0 04:00:00' DAY TO SECOND|\n",
      "|85                     |0.4                |1.1                  |vie    |INTERVAL '-0 01:00:00' DAY TO SECOND|\n",
      "|68                     |0.4                |0.0                  |sof    |INTERVAL '-0 02:00:00' DAY TO SECOND|\n",
      "|88                     |0.4                |2.1                  |ist    |NULL                                |\n",
      "|82                     |0.4                |0.7                  |sea    |NULL                                |\n",
      "|75                     |0.4                |1.3                  |saw    |NULL                                |\n",
      "|70                     |NULL               |NULL                 |pdv    |INTERVAL '-0 02:00:00' DAY TO SECOND|\n",
      "|81                     |0.9                |0.7                  |svo    |NULL                                |\n",
      "|62                     |NULL               |NULL                 |gbe    |INTERVAL '-0 02:00:00' DAY TO SECOND|\n",
      "|48                     |NULL               |NULL                 |lad    |INTERVAL '-0 01:00:00' DAY TO SECOND|\n",
      "|63                     |NULL               |NULL                 |bja    |INTERVAL '-0 01:00:00' DAY TO SECOND|\n",
      "|92                     |0.3                |1.7                  |lhr    |NULL                                |\n",
      "|78                     |0.5                |1.1                  |ord    |NULL                                |\n",
      "|73                     |NULL               |NULL                 |klu    |INTERVAL '-0 01:00:00' DAY TO SECOND|\n",
      "|78                     |5.0                |5.0                  |can    |NULL                                |\n",
      "+-----------------------+-------------------+---------------------+-------+------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the airports info processing function\n",
    "info_df = airports_info_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_processing():\n",
    "    \"\"\"\n",
    "    Processes weather data by cleaning and transforming specific columns.\n",
    "    This includes removing non-numeric characters, handling special cases in visibility,\n",
    "    and converting date_time strings to timestamp format.\n",
    "\n",
    "    Returns:\n",
    "        weather_df (DataFrame): A Spark DataFrame with processed weather information.\n",
    "    \"\"\"\n",
    "    # Initialize Spark Session with a specified app name and configuration\n",
    "    spark = SparkSession.builder.appName(\"WeatherDataProcessing\") \\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Define the schema for reading the CSV file\n",
    "    schema = StructType([\n",
    "        StructField(\"time\", StringType(), True),\n",
    "        StructField(\"temperature\", StringType(), True),\n",
    "        StructField(\"dew_point\", StringType(), True),\n",
    "        StructField(\"humidity\", StringType(), True),\n",
    "        StructField(\"wind\", StringType(), True),\n",
    "        StructField(\"wind_speed\", StringType(), True),\n",
    "        StructField(\"wind_gust\", StringType(), True),\n",
    "        StructField(\"pressure\", StringType(), True),\n",
    "        StructField(\"precip\", StringType(), True),\n",
    "        StructField(\"condition\", StringType(), True),\n",
    "        StructField(\"airport\", StringType(), True),\n",
    "        StructField(\"date\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "    # Load the data\n",
    "    weather_df = spark.read.csv('./data/history/weather.csv', schema=schema, header=False)\n",
    "\n",
    "    # Drop null values\n",
    "    weather_df = weather_df.dropna(how=\"any\")\n",
    "\n",
    "    # Clean numeric fields and cast to correct types\n",
    "    weather_df = weather_df.withColumn(\"temperature\", \n",
    "                                 regexp_replace(col(\"temperature\"), \"[^0-9-]\", \"\").cast(IntegerType())) \\\n",
    "                            .withColumn(\"dew_point\", \n",
    "                                 regexp_replace(col(\"dew_point\"), \"[^0-9-]\", \"\").cast(IntegerType())) \\\n",
    "                            .withColumn(\"humidity\", \n",
    "                                 regexp_replace(col(\"humidity\"), \"[^0-9]\", \"\").cast(IntegerType())) \\\n",
    "                            .withColumn(\"wind_speed\", \n",
    "                                 regexp_replace(col(\"wind_speed\"), \"[^0-9]\", \"\").cast(IntegerType())) \\\n",
    "                            .withColumn(\"wind_gust\", \n",
    "                                 regexp_replace(col(\"wind_gust\"), \"[^0-9]\", \"\").cast(IntegerType())) \\\n",
    "                            .withColumn(\"pressure\", \n",
    "                                 regexp_replace(col(\"pressure\"), \"[^0-9.]\", \"\").cast(FloatType())) \\\n",
    "                            .withColumn(\"precip\", \n",
    "                                 regexp_replace(col(\"precip\"), \"[^0-9.]\", \"\").cast(FloatType()))\n",
    "\n",
    "    \n",
    "\n",
    "    weather_df = weather_df.withColumn(\n",
    "        \"date_time\", \n",
    "        to_timestamp(concat_ws(\" \", split(col(\"date\"), \" \")[0], col(\"time\")), \"yyyy-MM-dd hh:mm a\")\n",
    "    ).drop(\"date\", \"time\")\n",
    "\n",
    "    # Remove duplicates\n",
    "    weather_df = weather_df.dropDuplicates()\n",
    "\n",
    "    # Add a new column 'rounded_hour' that represents the closest hour to date_time\n",
    "    weather_df = weather_df.withColumn(\"date\", to_date(\"date_time\")) \\\n",
    "        .withColumn(\"hour\", hour(\"date_time\")) \\\n",
    "        .withColumn(\"minute\", minute(\"date_time\")) \\\n",
    "        .withColumn(\"rounded_hour\",\n",
    "                        when(col(\"minute\") >= 30, expr(\"hour + 1\"))\n",
    "                        .otherwise(col(\"hour\"))\n",
    "                    ) \\\n",
    "        .drop(\"hour\", \"minute\")\n",
    "    \n",
    "    # Adjust for the case where adding 1 to the hour results in 24\n",
    "    weather_df = weather_df.withColumn(\"rounded_hour\",\n",
    "                    when(col(\"rounded_hour\") == 24, 0)\n",
    "                    .otherwise(col(\"rounded_hour\"))\n",
    "                    )\n",
    "\n",
    "    # Convert 'hour_column' to a string with two digits\n",
    "    rounded_hour = lpad(col(\"rounded_hour\"), 2, '0')\n",
    "    \n",
    "    # Concatenate 'date_column' and 'hour_str' to form a datetime string\n",
    "    datetime_str = concat_ws(\" \", col(\"date\"), rounded_hour)\n",
    "\n",
    "    # Append \":00:00\" to represent minutes and seconds, forming a full datetime string\n",
    "    datetime_str = concat_ws(\":\", datetime_str, lit(\"00\"), lit(\"00\"))\n",
    "\n",
    "    # Convert the datetime string to a timestamp\n",
    "    weather_df = weather_df.withColumn(\"rounded_hour\", to_timestamp(datetime_str, \"yyyy-MM-dd HH:mm:ss\")).drop('date')\n",
    "    \n",
    "    # Drop duplicate rounded_hour\n",
    "    weather_df = weather_df.dropDuplicates(['rounded_hour'])\n",
    "\n",
    "    '''\n",
    "    # Join the airports_info data with the aggregated weather data\n",
    "    weather_df = weather_df.join(info_df, \"airport\", \"left\")\n",
    "\n",
    "    # Converting weather date_time to local time using difference from joining info_df\n",
    "    weather_df = weather_df.withColumn(\"date_time\", expr(\"date_time - time_diff\")).drop(\"time_diff\")\n",
    "    '''\n",
    "    '''\n",
    "    # Aggregating wind direction, wind speed, temperature, dew point, pressure and visibility\n",
    "    weather_df = weather_df.groupBy(\"airport\", \"rounded_hour\").agg(\n",
    "        mean(\"wind_direction\").alias(\"wind_direction\"),\n",
    "        mean(\"wind_speed\").alias(\"wind_speed\"),\n",
    "        mean(\"temperature\").alias(\"temperature\"),\n",
    "        mean(\"dew_point\").alias(\"dew_point\"),\n",
    "        mean(\"pressure\").alias(\"pressure\"),\n",
    "        mean(\"visibility\").alias(\"visibility\"),\n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    # Check the schema of columns\n",
    "    weather_df.printSchema()\n",
    "        \n",
    "    # Display the processed DataFrame\n",
    "    weather_df.show(100, truncate=False)\n",
    "\n",
    "    # Return the processed DataFrame\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- temperature: integer (nullable = true)\n",
      " |-- dew_point: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind: string (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_gust: integer (nullable = true)\n",
      " |-- pressure: float (nullable = true)\n",
      " |-- precip: float (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- date_time: timestamp (nullable = true)\n",
      " |-- rounded_hour: timestamp (nullable = true)\n",
      "\n",
      "+-----------+---------+--------+----+----------+---------+--------+------+---------------------+-------+-------------------+-------------------+\n",
      "|temperature|dew_point|humidity|wind|wind_speed|wind_gust|pressure|precip|condition            |airport|date_time          |rounded_hour       |\n",
      "+-----------+---------+--------+----+----------+---------+--------+------+---------------------+-------+-------------------+-------------------+\n",
      "|68         |50       |52      |NNW |14        |0        |29.88   |0.0   |Fair                 |doh    |2023-04-02 00:00:00|2023-04-02 00:00:00|\n",
      "|68         |50       |52      |NNW |14        |25       |29.85   |0.0   |Fair                 |doh    |2023-04-02 00:30:00|2023-04-02 01:00:00|\n",
      "|75         |41       |29      |NNW |16        |0        |29.94   |0.0   |Fair                 |doh    |2023-04-02 11:30:00|2023-04-02 12:00:00|\n",
      "|77         |39       |26      |NNW |18        |32       |29.88   |0.0   |Fair                 |doh    |2023-04-02 13:00:00|2023-04-02 13:00:00|\n",
      "|68         |45       |43      |NW  |15        |0        |29.91   |0.0   |Fair                 |doh    |2023-04-02 18:30:00|2023-04-02 19:00:00|\n",
      "|66         |48       |52      |NW  |16        |0        |29.94   |0.0   |Fair                 |doh    |2023-04-02 21:00:00|2023-04-02 21:00:00|\n",
      "|36         |33       |89      |E   |3         |0        |29.49   |0.0   |Light Rain           |sea    |2023-04-03 01:12:00|2023-04-03 01:00:00|\n",
      "|72         |48       |43      |NNW |15        |26       |29.94   |0.0   |Fair                 |doh    |2023-04-03 08:30:00|2023-04-03 09:00:00|\n",
      "|77         |48       |36      |NNW |15        |28       |29.94   |0.0   |Fair                 |doh    |2023-04-03 10:30:00|2023-04-03 11:00:00|\n",
      "|77         |46       |34      |NW  |17        |0        |29.85   |0.0   |Fair                 |doh    |2023-04-03 16:00:00|2023-04-03 16:00:00|\n",
      "|41         |30       |65      |E   |7         |0        |30.3    |0.0   |Fair                 |lhr    |2023-04-03 22:20:00|2023-04-03 22:00:00|\n",
      "|70         |52       |53      |NW  |8         |0        |29.88   |0.0   |Fair                 |doh    |2023-04-04 01:00:00|2023-04-04 01:00:00|\n",
      "|68         |54       |60      |WNW |7         |0        |29.88   |0.0   |Fair                 |doh    |2023-04-04 04:00:00|2023-04-04 04:00:00|\n",
      "|50         |25       |37      |NNE |6         |0        |27.87   |0.0   |Fair                 |mad    |2023-04-04 10:00:00|2023-04-04 10:00:00|\n",
      "|54         |34       |47      |VAR |2         |0        |30.27   |0.0   |Fair                 |lhr    |2023-04-04 12:50:00|2023-04-04 13:00:00|\n",
      "|70         |9        |9       |NNE |12        |0        |27.81   |0.0   |Fair                 |mad    |2023-04-04 17:00:00|2023-04-04 17:00:00|\n",
      "|75         |73       |94      |ESE |4         |0        |29.68   |0.0   |Mostly Cloudy        |can    |2023-04-04 20:30:00|2023-04-04 21:00:00|\n",
      "|75         |73       |94      |SE  |9         |0        |29.68   |0.0   |Partly Cloudy        |can    |2023-04-05 03:30:00|2023-04-05 04:00:00|\n",
      "|68         |54       |60      |W   |5         |0        |29.85   |0.0   |Fair                 |doh    |2023-04-05 04:30:00|2023-04-05 05:00:00|\n",
      "|45         |36       |71      |SSW |7         |0        |30.09   |0.0   |Fair                 |lhr    |2023-04-05 08:50:00|2023-04-05 09:00:00|\n",
      "|45         |43       |93      |N   |13        |0        |29.52   |0.0   |Mostly Cloudy        |saw    |2023-04-05 10:20:00|2023-04-05 10:00:00|\n",
      "|58         |36       |44      |NNW |17        |21       |29.4    |0.0   |Mostly Cloudy        |dfw    |2023-04-05 11:53:00|2023-04-05 12:00:00|\n",
      "|55         |39       |54      |SW  |9         |0        |30.0    |0.0   |Mostly Cloudy        |lhr    |2023-04-05 15:50:00|2023-04-05 16:00:00|\n",
      "|48         |39       |71      |NNE |11        |0        |29.47   |0.0   |Fair                 |svo    |2023-04-05 18:00:00|2023-04-05 18:00:00|\n",
      "|45         |43       |93      |NNE |13        |0        |29.58   |0.0   |Mostly Cloudy        |saw    |2023-04-05 19:20:00|2023-04-05 19:00:00|\n",
      "|73         |73       |100     |NE  |4         |0        |29.77   |0.0   |Light Rain Shower    |can    |2023-04-06 07:00:00|2023-04-06 07:00:00|\n",
      "|52         |48       |88      |W   |14        |0        |29.8    |0.0   |Cloudy               |lhr    |2023-04-06 09:20:00|2023-04-06 09:00:00|\n",
      "|55         |27       |33      |N   |2         |0        |27.98   |0.0   |Fair                 |mad    |2023-04-06 11:00:00|2023-04-06 11:00:00|\n",
      "|70         |25       |18      |ESE |5         |0        |27.95   |0.0   |Fair                 |mad    |2023-04-06 14:30:00|2023-04-06 15:00:00|\n",
      "|50         |46       |86      |E   |10        |0        |29.31   |0.1   |Light Rain           |sea    |2023-04-06 18:53:00|2023-04-06 19:00:00|\n",
      "|50         |48       |94      |NNE |9         |0        |29.52   |0.0   |Light Rain Shower    |saw    |2023-04-06 20:50:00|2023-04-06 21:00:00|\n",
      "|68         |63       |83      |SW  |2         |0        |29.85   |0.0   |Fair                 |doh    |2023-04-07 05:30:00|2023-04-07 06:00:00|\n",
      "|50         |45       |82      |NE  |12        |0        |29.67   |0.0   |Mostly Cloudy        |saw    |2023-04-07 12:50:00|2023-04-07 13:00:00|\n",
      "|59         |36       |42      |N   |5         |0        |30.06   |0.0   |Fair                 |lhr    |2023-04-07 15:20:00|2023-04-07 15:00:00|\n",
      "|48         |45       |87      |NE  |12        |0        |29.72   |0.0   |Partly Cloudy        |saw    |2023-04-07 19:50:00|2023-04-07 20:00:00|\n",
      "|39         |25       |56      |E   |9         |0        |29.64   |0.0   |Fair                 |svo    |2023-04-07 22:30:00|2023-04-07 23:00:00|\n",
      "|28         |25       |86      |NNE |6         |0        |30.29   |0.0   |Fair                 |arn    |2023-04-08 06:50:00|2023-04-08 07:00:00|\n",
      "|37         |25       |60      |E   |9         |0        |29.67   |0.0   |Fair                 |svo    |2023-04-08 08:00:00|2023-04-08 08:00:00|\n",
      "|56         |48       |75      |NNE |5         |0        |30.13   |0.0   |Mostly Cloudy        |sfo    |2023-04-08 10:56:00|2023-04-08 11:00:00|\n",
      "|52         |27       |38      |SSE |4         |16       |29.64   |0.0   |Fair                 |svo    |2023-04-08 13:00:00|2023-04-08 13:00:00|\n",
      "|59         |37       |45      |ENE |7         |0        |30.18   |0.0   |Fair                 |lhr    |2023-04-08 15:50:00|2023-04-08 16:00:00|\n",
      "|72         |27       |19      |WSW |8         |0        |27.89   |0.0   |Fair                 |mad    |2023-04-08 21:30:00|2023-04-08 22:00:00|\n",
      "|74         |69       |85      |WNW |5         |0        |29.97   |0.0   |Mostly Cloudy        |mia    |2023-04-09 03:53:00|2023-04-09 04:00:00|\n",
      "|50         |34       |54      |VAR |2         |0        |27.98   |0.0   |Fair                 |mad    |2023-04-09 04:30:00|2023-04-09 05:00:00|\n",
      "|72         |32       |23      |WNW |6         |0        |28.0    |0.0   |Fair                 |mad    |2023-04-09 22:00:00|2023-04-09 22:00:00|\n",
      "|46         |41       |83      |ESE |9         |0        |29.63   |0.0   |Cloudy               |sea    |2023-04-10 05:32:00|2023-04-10 06:00:00|\n",
      "|52         |52       |100     |SSW |15        |0        |29.68   |0.0   |Rain                 |lhr    |2023-04-10 10:50:00|2023-04-10 11:00:00|\n",
      "|68         |37       |33      |S   |2         |0        |28.09   |0.0   |Fair                 |mad    |2023-04-10 12:00:00|2023-04-10 12:00:00|\n",
      "|84         |57       |40      |SE  |13        |0        |29.82   |0.0   |Fair                 |doh    |2023-04-10 14:30:00|2023-04-10 15:00:00|\n",
      "|58         |30       |35      |ESE |3         |0        |29.57   |0.0   |Fair                 |clt    |2023-04-10 20:52:00|2023-04-10 21:00:00|\n",
      "|48         |46       |93      |NW  |5         |0        |29.43   |0.0   |Rain Shower          |saw    |2023-04-11 05:20:00|2023-04-11 05:00:00|\n",
      "|46         |34       |62      |VAR |1         |0        |28.06   |0.0   |Fair                 |mad    |2023-04-11 06:00:00|2023-04-11 06:00:00|\n",
      "|50         |33       |52      |SSW |18        |30       |29.59   |0.0   |Partly Cloudy        |sea    |2023-04-11 13:53:00|2023-04-11 14:00:00|\n",
      "|48         |48       |100     |WSW |14        |0        |29.34   |0.0   |Rain Shower          |saw    |2023-04-11 19:12:00|2023-04-11 19:00:00|\n",
      "|39         |34       |81      |E   |8         |0        |29.68   |0.0   |Fair                 |arn    |2023-04-12 01:20:00|2023-04-12 01:00:00|\n",
      "|48         |48       |100     |WSW |10        |0        |29.29   |0.0   |Light Rain Shower    |saw    |2023-04-12 06:50:00|2023-04-12 07:00:00|\n",
      "|48         |48       |100     |WSW |15        |0        |29.29   |0.0   |Rain Shower          |saw    |2023-04-12 08:20:00|2023-04-12 08:00:00|\n",
      "|59         |41       |51      |SSE |14        |0        |29.68   |0.0   |Fair                 |arn    |2023-04-12 13:50:00|2023-04-12 14:00:00|\n",
      "|68         |39       |35      |W   |22        |0        |27.81   |0.0   |Partly Cloudy / Windy|mad    |2023-04-12 17:00:00|2023-04-12 17:00:00|\n",
      "|45         |39       |81      |SW  |14        |0        |29.12   |0.0   |Light Rain           |lhr    |2023-04-12 20:20:00|2023-04-12 20:00:00|\n",
      "|81         |64       |58      |E   |12        |0        |29.79   |0.0   |Fair                 |doh    |2023-04-12 23:00:00|2023-04-12 23:00:00|\n",
      "|45         |36       |71      |WSW |17        |0        |29.38   |0.0   |Fair                 |lhr    |2023-04-13 04:50:00|2023-04-13 05:00:00|\n",
      "|46         |36       |66      |W   |16        |0        |29.47   |0.0   |Fair                 |lhr    |2023-04-13 08:50:00|2023-04-13 09:00:00|\n",
      "|54         |28       |38      |SW  |3         |0        |27.98   |0.0   |Fair                 |mad    |2023-04-13 11:00:00|2023-04-13 11:00:00|\n",
      "|55         |30       |38      |SE  |1         |0        |27.98   |0.0   |Fair                 |mad    |2023-04-13 11:30:00|2023-04-13 12:00:00|\n",
      "|61         |41       |48      |SE  |5         |0        |29.68   |0.0   |Fair                 |ist    |2023-04-13 17:50:00|2023-04-13 18:00:00|\n",
      "|73         |51       |46      |S   |15        |0        |29.07   |0.0   |Fair                 |dfw    |2023-04-13 19:53:00|2023-04-13 20:00:00|\n",
      "|61         |37       |42      |ESE |3         |0        |29.52   |0.0   |Fair                 |saw    |2023-04-13 20:50:00|2023-04-13 21:00:00|\n",
      "|65         |51       |61      |SSE |9         |0        |29.09   |0.0   |Partly Cloudy        |dfw    |2023-04-14 00:53:00|2023-04-14 01:00:00|\n",
      "|75         |70       |83      |N   |16        |0        |29.91   |0.0   |Cloudy               |doh    |2023-04-14 04:00:00|2023-04-14 04:00:00|\n",
      "|75         |68       |78      |SW  |7         |0        |30.0    |0.0   |Light Rain           |doh    |2023-04-14 05:30:00|2023-04-14 06:00:00|\n",
      "|66         |43       |43      |W   |21        |0        |27.87   |0.0   |Partly Cloudy / Windy|mad    |2023-04-14 19:00:00|2023-04-14 19:00:00|\n",
      "|45         |43       |93      |N   |6         |0        |29.68   |0.0   |Light Rain           |lhr    |2023-04-15 00:20:00|2023-04-15 00:00:00|\n",
      "|46         |43       |87      |N   |7         |0        |29.88   |0.0   |Light Rain           |lhr    |2023-04-15 07:50:00|2023-04-15 08:00:00|\n",
      "|54         |41       |62      |SSE |5         |0        |28.03   |0.0   |Fair                 |mad    |2023-04-15 09:30:00|2023-04-15 10:00:00|\n",
      "|82         |43       |25      |NNW |22        |0        |29.94   |0.0   |Fair / Windy         |doh    |2023-04-15 12:00:00|2023-04-15 12:00:00|\n",
      "|49         |43       |80      |WSW |5         |0        |29.66   |0.0   |Cloudy               |sea    |2023-04-15 15:53:00|2023-04-15 16:00:00|\n",
      "|52         |43       |71      |VAR |2         |0        |30.15   |0.0   |Mostly Cloudy        |lhr    |2023-04-15 21:20:00|2023-04-15 21:00:00|\n",
      "|32         |14       |48      |E   |9         |0        |29.76   |0.0   |Fair                 |svo    |2023-04-16 04:30:00|2023-04-16 05:00:00|\n",
      "|50         |39       |66      |ESE |5         |0        |28.06   |0.0   |Fair                 |mad    |2023-04-16 07:30:00|2023-04-16 08:00:00|\n",
      "|47         |43       |86      |SSW |10        |0        |29.45   |0.0   |Light Rain           |sea    |2023-04-16 13:53:00|2023-04-16 14:00:00|\n",
      "|54         |12       |19      |SSE |11        |0        |29.7    |0.0   |Fair                 |svo    |2023-04-16 14:30:00|2023-04-16 15:00:00|\n",
      "|77         |27       |16      |N   |8         |0        |27.92   |0.0   |Fair                 |mad    |2023-04-16 19:30:00|2023-04-16 20:00:00|\n",
      "|52         |46       |82      |NE  |2         |0        |30.24   |0.0   |Mostly Cloudy        |lhr    |2023-04-17 05:50:00|2023-04-17 06:00:00|\n",
      "|57         |46       |67      |E   |13        |0        |30.24   |0.0   |Fair                 |lhr    |2023-04-17 18:50:00|2023-04-17 19:00:00|\n",
      "|48         |45       |87      |E   |9         |0        |30.3    |0.0   |Fair                 |lhr    |2023-04-17 21:20:00|2023-04-17 21:00:00|\n",
      "|73         |63       |69      |WSW |3         |0        |29.82   |0.0   |Fair                 |doh    |2023-04-18 04:30:00|2023-04-18 05:00:00|\n",
      "|48         |30       |50      |NNW |6         |0        |27.84   |0.0   |Fair                 |mad    |2023-04-18 05:30:00|2023-04-18 06:00:00|\n",
      "|56         |51       |84      |W   |5         |0        |29.86   |0.0   |Mostly Cloudy        |lax    |2023-04-18 07:09:00|2023-04-18 07:00:00|\n",
      "|38         |27       |65      |W   |9         |0        |29.17   |0.0   |Fair                 |ord    |2023-04-18 07:51:00|2023-04-18 08:00:00|\n",
      "|46         |43       |87      |NE  |6         |0        |30.18   |0.0   |Fair                 |lhr    |2023-04-19 03:50:00|2023-04-19 04:00:00|\n",
      "|79         |77       |94      |ESE |7         |0        |29.6    |0.0   |Mostly Cloudy        |can    |2023-04-19 05:00:00|2023-04-19 05:00:00|\n",
      "|88         |46       |24      |VAR |3         |0        |29.91   |0.0   |Fair                 |doh    |2023-04-19 09:30:00|2023-04-19 10:00:00|\n",
      "|57         |52       |82      |W   |13        |0        |29.52   |0.0   |Mostly Cloudy        |saw    |2023-04-19 10:50:00|2023-04-19 11:00:00|\n",
      "|61         |52       |72      |VAR |3         |0        |29.49   |0.0   |Partly Cloudy        |saw    |2023-04-19 18:20:00|2023-04-19 18:00:00|\n",
      "|55         |25       |31      |NE  |11        |0        |29.59   |0.0   |Fair                 |svo    |2023-04-19 20:30:00|2023-04-19 21:00:00|\n",
      "|37         |32       |82      |CALM|0         |0        |29.88   |0.0   |Mostly Cloudy        |sea    |2023-04-20 02:53:00|2023-04-20 03:00:00|\n",
      "|72         |64       |76      |S   |17        |26       |29.19   |0.0   |Cloudy               |dfw    |2023-04-20 03:53:00|2023-04-20 04:00:00|\n",
      "|84         |75       |74      |VAR |2         |0        |29.6    |0.0   |Fair                 |can    |2023-04-20 11:00:00|2023-04-20 11:00:00|\n",
      "|55         |52       |88      |S   |3         |0        |29.55   |0.0   |Mostly Cloudy        |saw    |2023-04-21 00:20:00|2023-04-21 00:00:00|\n",
      "+-----------+---------+--------+----+----------+---------+--------+------+---------------------+-------+-------------------+-------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the weather processing function\n",
    "weather_df = weather_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_processing():\n",
    "    \"\"\"\n",
    "    Cleans review data from a CSV file. This function lowercases comments, removes special characters,\n",
    "    filters out empty comments, and removes duplicate rows. It initializes a Spark session, reads the data using\n",
    "    a predefined schema, and applies text preprocessing to the 'comment' field. The cleaned DataFrame is then returned.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The processed reviews DataFrame.\n",
    "    \"\"\"\n",
    "    # Initialization and data loading\n",
    "    spark = SparkSession.builder.appName(\"ReviewsDataProcessing\")\\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\\\n",
    "        .getOrCreate()\n",
    "    schema = StructType([\n",
    "        StructField(\"comment\", StringType(), True),\n",
    "        StructField(\"airport\", StringType(), True),\n",
    "    ])\n",
    "    reviews_df = spark.read.csv('./data/history/reviews.csv', schema=schema, header=False)\n",
    "\n",
    "    # Data cleaning and preprocessing\n",
    "    reviews_df = reviews_df.withColumn(\"comment\", lower(col(\"comment\")))\n",
    "    reviews_df = reviews_df.withColumn(\"comment\", regexp_replace(col(\"comment\"), \"[^a-zA-Z0-9 ]\", \"\"))\n",
    "    reviews_df = reviews_df.filter(trim(col(\"comment\")) != \"\")\n",
    "    reviews_df = reviews_df.dropDuplicates()\n",
    "\n",
    "    path = \"./data/processed/reviews\"\n",
    "    reviews_df.coalesce(1).write.csv(path=path, mode=\"overwrite\", header=True)\n",
    "\n",
    "    # Show and return the processed DataFrame\n",
    "    reviews_df.show(truncate=False)\n",
    "\n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|comment                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |airport|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|modern airport though called for boarding and then waited in a line for over 40 minutes at security as no security staff were there                                                                                                                                                                                                                                                                                                                                                                                                                                                     |vie    |\n",
      "|this is one of the most beautiful airports i have ever seen i had to catch connecting flight from uk to pl and only had 50 min between flights i have managed to be on time there was a board with connecting flights just as we arrived to the gate  and it was showing where to go airport was very nice and clean with loads of shops and bars                                                                                                                                                                                                                                       |cph    |\n",
      "|one of the best airports  with incredible easy check in and fast security check easy to reach  free unlimited wifi with great signal                                                                                                                                                                                                                                                                                                                                                                                                                                                    |hel    |\n",
      "|security check is slow all flights end up to the same security check on arrival if you want to go to the french side watch the signs it is easy to get wrong and land in the swiss side going back to the french side is a pain                                                                                                                                                                                                                                                                                                                                                         |bsl    |\n",
      "|flight took from the terminal 3  which seems to be a more peaceful terminal than the terminal 2 no too much people and only one security check not much food facilities  though                                                                                                                                                                                                                                                                                                                                                                                                         |cdg    |\n",
      "|af lounge discontinued its service for skyteam elite plus members which make a whole idea of aria alliances a joke                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |cdg    |\n",
      "|this rate is concerning to t2 of g aliev airpot which is much more worse than t1 which is wonderful                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |gyd    |\n",
      "|always have to wait too long for bags 40 mins today                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |bru    |\n",
      "|small airport                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |boj    |\n",
      "|terminal 2 is clean  warm and pleasant the sterile zone shines the staff is extremely friendly  polite and helping to all for everything this is one of my favorite european airports                                                                                                                                                                                                                                                                                                                                                                                                   |sof    |\n",
      "|very small and nice airport it has some restaurants and shops if you are waiting for 30 minutes its perfect                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |var    |\n",
      "|kleiner airport  sauber  effizient und freundlich mit gutem dutyfreeshop fr whiskyfans                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |pfo    |\n",
      "|aarhus airport is the best airport i know  not because they have loads of shops that i like or anything like that they only have two  one before security and one after but i still yet love this regional airport  its once again the best airport ive ever known customs were quick  mainly because there werent any the baggage arrived fast aswell                                                                                                                                                                                                                                  |aar    |\n",
      "|gemchliche geschwindigkeit des personals wartezeit auf das gepck war recht lange wifi kostenlos aber nicht recht stabil taxi unverhltnismig teuer busanbindung nicht berauschend  wrde ich aber bevorzugen                                                                                                                                                                                                                                                                                                                                                                              |nce    |\n",
      "|otherwise good airport  but terminal 2 has poor services for example the lack of self service kiosks for checkin is rather strange for such a new facility taxfree selection is minimal in case you wish to have something else than the most popular alcohols or fragrances                                                                                                                                                                                                                                                                                                            |nce    |\n",
      "|the absolute worst airport ive ever been in ive been in 30 there is so much useless staff they cant even justify their purpose they check the ticket 5 times before getting to the gate  not an exaggeration  literally i counted 5 times most of the staff doesnt speak more than 2 words in english only 2 working border control desks for the whole terminal not to mention the whole airport is one cheap hangar with minimal improvements though they claim its a paris airport  its very far away and it is very poorly connected to the city  even to the beauvais train station|bva    |\n",
      "|nice small airport                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |grz    |\n",
      "|very unsexy airport chaotig facilities and parking situation food court available but extremely narrow and crowded much to less seats at the gates leaving the flight within rain is a mess  complete foodway hasnt a roof signs for parking quite rare even if booked a parking fe at p2 you have to circle and circle to find a parking lot or wait until someone leaves trashy                                                                                                                                                                                                       |crl    |\n",
      "|new terminal  four times bigger than the last one  fast  safe  without any problems  two ways how to get to the airport with public transport staff very polite big plus for new terminal                                                                                                                                                                                                                                                                                                                                                                                               |zag    |\n",
      "|nice hot weather  sunny day  nice new airport and perfekt holiday location                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |lca    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df = reviews_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544760\n"
     ]
    }
   ],
   "source": [
    "print(flights_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Joining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the flights data with the aggregated weather data\n",
    "#joined_df = flights_df.join(weather_df, [\"rounded_hour\", \"airport\"], \"left\")\n",
    "\n",
    "# Join flights data with airports info\n",
    "#joined_df = joined_df.join(info_df, [\"airport\"], \"left\").drop(\"time_diff\")\n",
    "\n",
    "\n",
    "# Join flights data with aircrafts info\n",
    "#joined_df = joined_df.join(aircraft_info_df, [\"aircraft\"], \"left\")\n",
    "\n",
    "#print(joined_df.count())\n",
    "\n",
    "# Check the schema of columns\n",
    "#joined_df.printSchema()\n",
    "\n",
    "# Display the result to verify the join\n",
    "#joined_df.where(joined_df.airport == 'doh').show(1000, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Saving output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/processed/joined\"\n",
    "flights_df.coalesce(1).write.csv(path=path, mode=\"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    ".\n",
    "\n",
    "---\n",
    "\n",
    "## Change Log\n",
    "- **Version 1.0** [Date]: Initial version of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
